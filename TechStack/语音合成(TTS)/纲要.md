# 语音合成(TTS)研究领域全面学习路线图

这份路线图将帮助你从入门到达到10年经验的资深水平。笔记采用Obsidian格式，包含各类知识点的内部链接，方便你构建自己的知识网络。

## 🔍 目录

- [[#基础学科知识]]
- [[#语音合成基础理论]]
- [[#传统语音合成方法]]
- [[#深度学习语音合成方法]]
- [[#进阶研究方向]]
- [[#工程实践技能]]
- [[#评估方法]]
- [[#行业应用]]
- [[#科研与职业发展]]
- [[#学习资源]]

---

## 基础学科知识

### 📊 数学基础

- **线性代数**
    - 矩阵运算与分解
    - 特征值与特征向量
    - SVD分解及其在语音信号处理中的应用
- **概率与统计**
    - 概率分布（尤其是高斯分布）
    - 贝叶斯理论
    - 极大似然估计
    - 期望最大化算法(EM)
- **优化理论**
    - 梯度下降及其变体
    - 拉格朗日乘子法
    - 凸优化
- **信息论**
    - 熵与互信息
    - KL散度
    - 信息瓶颈原理

### 🎵 信号处理

- **时域分析**
    - 采样定理
    - 窗函数设计
    - 自相关分析
- **频域分析**
    - [[傅里叶变换]]（DFT，FFT）
    - [[短时傅里叶变换]]（STFT）
    - 小波变换
- **滤波器设计**
    - FIR与IIR滤波器
    - 梳状滤波器
    - 线性预测分析(LPC)
- **频谱分析技术**
    - 倒谱分析
    - 梅尔频谱
    - 线性预测倒谱系数(LPCC)
    - 梅尔频率倒谱系数(MFCC)

### 🗣️ 语音学

- **发音机制**
    - 声道结构与功能
    - 声门激励模型
    - 共振峰理论
- **音素学**
    - 国际音标(IPA)
    - 各语言音素系统对比
    - 音素-音素转换规则
- **韵律学**
    - 基频(F0)特性
    - 音长控制因素
    - 重音与语调模式
    - 停顿规律
- **语音感知**
    - 听觉模型
    - 掩蔽效应
    - 临界带

### 💻 计算机科学基础

- **编程语言**
    - Python（主要用于研究原型）
    - C++（用于性能优化）
    - MATLAB（用于信号处理）
- **算法与数据结构**
    - 复杂度分析
    - 动态规划
    - 图算法（用于单元选择）
- **并行计算**
    - GPU编程基础(CUDA)
    - 分布式训练框架

---

## 语音合成基础理论

### 🔊 语音信号特性

- **声学参数**
    - 基频(F0)提取算法
        - 自相关法
        - RAPT
        - WORLD's Harvest
        - PYIN算法
    - 能量计算
    - 频谱包络估计
    - 声源-滤波器模型
- **语音参数化方法**
    - 线性预测系数(LPC)
    - 线谱对(LSP)
    - 梅尔倒谱系数(MCEP)
    - 声码器参数（如WORLD的参数）

### 📝 文本分析

- **文本预处理**
    - 文本规范化
    - 数字、缩写、符号处理
    - 多语言文本处理
- **词性标注**
    - 统计方法
    - 神经网络方法
- **分词技术**
    - 基于规则的方法
    - 统计方法
    - 深度学习方法
- **G2P转换**
    - 规则库方法
    - 统计方法
    - 序列到序列模型
- **韵律标注**
    - ToBI系统
    - 韵律结构预测

---

## 传统语音合成方法

### 📚 拼接合成(Unit Selection)

- **单元设计**
    - 二音子(Diphone)
    - 半音节(Demisyllable)
    - 音素(Phone)变体
    - 变长单元
- **语料库设计**
    - 语音录制规范
    - 覆盖度与平衡性
    - 标注方法
- **单元选择算法**
    - 目标代价设计
    - 连接代价设计
    - 维特比搜索
    - 剪枝技术
- **波形处理**
    - PSOLA算法
    - 接缝平滑技术
    - 相位一致性处理

### 🔄 参数合成

- **统计参数合成**
    - HMM基础
    - 决策树聚类
    - 参数生成算法
    - 全局方差(GV)增强
- **混合激励模型**
    - 多带激励
    - 残差补偿
- **声码器**
    - STRAIGHT
    - WORLD
    - 传统滤波器组

### 🤖 规则合成

- **formant合成**
    - 共振峰轨迹生成
    - 激励信号设计
- **算法合成**
    - Klatt合成器
    - FOF合成

---

## 深度学习语音合成方法

### 🧠 神经网络基础

- **前馈神经网络**
    - 多层感知机
    - 激活函数选择
    - 正则化技术
- **循环神经网络**
    - LSTM
    - GRU
    - 双向RNN
- **注意力机制**
    - 点积注意力
    - 位置编码
    - 多头注意力
- **Transformer架构**
    - 自注意力层
    - 前馈层
    - 位置编码
    - 解码策略

### 🌊 自回归模型

- **WaveNet**
    - 扩张卷积
    - 条件WaveNet
    - 快速生成技术
- **SampleRNN**
    - 多层次结构
    - 训练技巧
- **WaveRNN**
    - 稀疏WaveRNN
    - 二分类量化
    - 并行生成策略

### 🔄 端到端模型

- **Tacotron系列**
    - Tacotron架构
    - Tacotron 2改进
    - GST (Global Style Tokens)
    - Reference Encoder
- **FastSpeech系列**
    - 持续时间预测器
    - 非自回归生成
    - FastSpeech 2改进
    - 变分推理技术
- **VITS**
    - 隐变量模型
    - 条件流模型
    - 随机持续时间预测

### 🌀 扩散模型

- **Diff-SVC**
    - 噪声调度
    - 反向扩散过程
    - 条件控制
- **Grad-TTS**
    - 梯度引导生成
    - 速度控制技术
- **DiffWave**
    - 波形域扩散
    - 加速采样策略

### 🎭 GAN模型

- **GAN-TTS**
    - 多分辨率STFT判别器
    - 适用于TTS的GAN训练技巧
- **MelGAN**
    - 快速推理技术
    - 多尺度判别器
- **HiFi-GAN**
    - 周期性判别器
    - 多接收野判别器

### 🎵 神经声码器

- **WaveGlow**
    - 流模型基础
    - 仿射耦合层
- **Parallel WaveGAN**
    - 多分辨率STFT损失
    - 高效并行生成
- **UnivNet**
    - 条件卷积设计
    - 频谱相似性感知损失
- **NSF模型**
    - 正弦激励设计
    - 谐波增强技术

---

## 进阶研究方向

### 🌐 多语言/跨语言语音合成

- **语言共享参数**
    - 共享编码器策略
    - 语言标记方法
- **零资源语音合成**
    - 跨语言知识迁移
    - 元学习方法
- **代码切换TTS**
    - 混合语言建模
    - 语音风格保持

### 😀 表现力语音合成

- **情感建模**
    - 离散情感分类
    - 连续情感空间
    - VAE情感表示
- **说话风格迁移**
    - 参考音频编码
    - 风格令牌学习
    - 样式瓶颈层
- **韵律控制**
    - 相控模型
    - 韵律嵌入学习
    - 显式韵律控制接口

### 🎯 个性化语音合成

- **说话人自适应**
    - i-vector方法
    - 微调技术
    - 元学习方法
- **少样本学习**
    - 原型网络
    - 参数高效微调(PEFT)
    - LoRA适配
- **说话人嵌入**
    - d-vector
    - x-vector
    - ECAPA-TDNN

### 🔄 语音转换

- **声码器重合成方法**
    - WORLD参数映射
    - StarGAN-VC
- **CycleGAN方法**
    - 循环一致性约束
    - 不成对数据训练
- **自监督语音表示**
    - wav2vec 2.0
    - HuBERT
    - WavLM
- **零样本语音转换**
    - AUTOVC
    - 不同说话人间的声音与内容解耦

### 🧩 混合与融合方法

- **神经-参数混合系统**
    - DNN-HMM混合架构
    - 神经网络与拼接合成融合
- **多模型集成**
    - 模型蒸馏
    - 级联架构
    - 多专家混合

### 📉 轻量化与高效推理

- **知识蒸馏**
    - 教师-学生框架
    - 特征蒸馏
- **模型量化**
    - 整数量化
    - 混合精度量化
- **模型剪枝**
    - 结构化剪枝
    - 非结构化剪枝
- **神经架构搜索(NAS)**
    - 超网络
    - 可微分架构搜索

---

## 工程实践技能

### 🛠️ 开发环境

- **深度学习框架**
    - PyTorch
    - TensorFlow/Keras
    - JAX生态系统
- **TTS工具包**
    - ESPnet
    - Kaldi
    - Montreal Forced Aligner
    - Festival/Merlin
- **声学分析工具**
    - Praat
    - WaveSurfer
    - openSMILE

### 📊 数据处理

- **语音数据库**
    - LJSpeech
    - CSTR VCTK
    - LibriTTS
    - 中文数据集（如标贝、魔奇、AIShell-3）
- **数据增强**
    - 速度扰动
    - SpecAugment
    - 噪声混合
- **数据清洗**
    - 自动切分
    - 音频质量评估
    - 异常检测
- **标注技术**
    - 强制对齐
    - 半自动标注
    - 主动学习

### 🧪 实验设计

- **实验管理**
    - 版本控制(Git)
    - 实验跟踪(MLflow, Weights & Biases)
    - 超参数搜索
- **评估设计**
    - AB测试设计
    - MOS评估设计
    - 众包评估平台使用
- **复现研究**
    - 论文实现技巧
    - 基线系统建立
    - 消融实验设计

### 🚀 部署优化

- **推理加速**
    - ONNX转换
    - TensorRT优化
    - 批处理技术
- **移动端部署**
    - TFLite优化
    - CoreML转换
    - 模型分段处理
- **服务端架构**
    - REST API设计
    - 流式处理
    - 负载均衡

---

## 评估方法

### 📏 客观评估

- **频谱距离度量**
    - 梅尔倒谱失真(MCD)
    - 频谱收敛度
- **基频评估**
    - RMSE
    - 相关系数
    - Gross pitch error
- **时长评估**
    - 音素持续时间RMSE
    - 语速评估
- **ASR评估**
    - 字符错误率(CER)
    - 词错误率(WER)
- **可懂度测试**
    - 语音转写测试
    - 听写测试
    - 声学混淆度

### 👂 主观评估

- **平均意见得分(MOS)**
    - 自然度MOS
    - 相似度MOS
    - 整体质量MOS
- **对比测试**
    - AB测试
    - ABX测试
    - MUSHRA
    - CCR(比较类别评分)
- **DMOS**
    - 降级平均意见得分
- **专家评估**
    - 音系准确度
    - 韵律合适度
    - 表现力评价

### 🤖 自动评估

- **MOSNet**
    - 自动MOS预测
    - 多维质量评估
- **FAD (Fréchet Audio Distance)**
    - 分布相似度评估
- **质量与相似度自动评分**
    - AutoMOS
    - 嵌入空间距离度量

---

## 行业应用

### 🔊 商业系统案例分析

- **主流商业TTS系统**
    - Amazon Polly
    - Google WaveNet/Tacotron
    - Microsoft Neural TTS
    - 科大讯飞
    - 百度飞桨
- **开源系统**
    - Mozilla TTS
    - Coqui TTS
    - ESPnet-TTS
    - NVIDIA NeMo

### 🎯 应用场景

- **智能助手**
    - 交互式语音设计
    - 上下文敏感合成
- **内容朗读**
    - 长文本处理
    - 章节段落处理
- **导航提示**
    - 实时生成
    - 高可懂度优化
- **游戏与娱乐**
    - 角色语音设计
    - 动态内容生成
- **无障碍应用**
    - 屏幕阅读器优化
    - 语速控制

### 💼 产品化考量

- **实时性要求**
    - 延迟控制
    - 流式处理设计
- **计算资源平衡**
    - 服务器端部署
    - 边缘计算优化
    - 终端设备优化
- **多语言支持**
    - 语言切换
    - 口音控制
    - 国际化部署
- **用户体验设计**
    - TTS交互范式
    - 语音界面指南

---

## 科研与职业发展

### 📚 学术研究

- **顶级会议**
    - ICASSP
    - Interspeech
    - IEEE SLT
    - NeurIPS/ICLR/ICML (ML方向)
- **期刊**
    - IEEE/ACM TASLP
    - Speech Communication
    - Computer Speech & Language
- **科研写作**
    - 论文结构
    - 实验设计与验证
    - 审稿回应技巧
- **评测活动**
    - Blizzard Challenge
    - Voice Conversion Challenge
    - ASVspoof Challenge

### 🏢 工业界趋势

- **市场现状**
    - 垂直领域应用
    - 平台生态
    - 许可模式
- **创业机会**
    - 垂直行业定制
    - 个性化服务
    - 开发工具链
- **开源社区**
    - 参与贡献
    - 项目维护
    - 社区建设

### 🚀 发展路径

- **研究方向选择**
    - 跟踪前沿趋势
    - 找准研究空白
    - 建立研究特色
- **技能积累**
    - 阶段性目标设定
    - 核心竞争力构建
    - 交叉学科拓展
- **职业规划**
    - 学术路径
    - 工业界路径
    - 创业路径

---

## 学习资源

### 📖 经典教材

- **语音信号处理**
    - 《Digital Processing of Speech Signals》- Rabiner & Schafer
    - 《Speech and Audio Signal Processing》- Gold & Morgan
- **语音合成**
    - 《Text-to-Speech Synthesis》- Taylor
    - 《Statistical Parametric Speech Synthesis》- Zen et al.
    - 《深度学习语音合成》- 中国科大语音实验室
- **深度学习**
    - 《Deep Learning》- Goodfellow, Bengio, & Courville
    - 《Speech and Language Processing》- Jurafsky & Martin

### 🌐 在线课程

- **语音处理基础**
    - Speech Processing (Edinburgh University)
    - Digital Signal Processing (MIT OpenCourseWare)
- **语音合成专题**
    - CS224S (Stanford)
    - Speech Synthesis Lectures (CMU)
- **深度学习**
    - deeplearning.ai课程
    - fast.ai课程

### 💻 实践资源

- **GitHub仓库**
    - ESPnet (语音合成工具包)
    - Kaldi (语音处理工具包)
    - HuggingFace (预训练模型)
- **数据集**
    - LJSpeech (英语单人)
    - VCTK (英语多人)
    - LibriTTS (英语有声书)
    - AIShell-3 (中文TTS数据集)
    - CSS10 (多语言)
- **公开API**
    - Google Cloud TTS
    - Microsoft Azure TTS
    - Amazon Polly

### 🔎 进阶研究阅读

- **经典论文**
    - WaveNet (van den Oord et al.)
    - Tacotron (Wang et al.)
    - FastSpeech (Ren et al.)
    - VITS (Kim et al.)
- **综述论文**
    - 《Statistical Parametric Speech Synthesis》(Zen et al.)
    - 《Neural speech synthesis》(Tan et al.)
    - 《Neural approaches to conversational AI》(Gao et al.)

---

## 学习计划与里程碑

### 🌱 入门阶段 (0-1年)

- **目标**：掌握基础理论，能复现简单模型
- **学习重点**
    - 信号处理基础
    - 语音学入门
    - Python编程
    - 基本深度学习框架使用
- **实践项目**
    - 实现简单的HMM合成系统
    - 复现Tacotron或FastSpeech
    - 使用开源声码器

### 🚀 成长阶段 (1-3年)

- **目标**：掌握主流技术，能独立开发系统
- **学习重点**
    - 深度TTS模型内部机制
    - 语音信号处理高级技术
    - 实验设计与评估
- **实践项目**
    - 开发完整的端到端TTS系统
    - 参与开源项目贡献
    - 尝试发表会议论文

### 🔍 专业阶段 (3-5年)

- **目标**：形成专业特色，解决复杂问题
- **学习重点**
    - 某一细分领域深入研究
    - 跨领域知识整合
    - 工程化与产品化能力
- **实践项目**
    - 解决特定场景下的TTS挑战
    - 发表高质量学术论文
    - 开发创新型TTS组件

### 🏆 资深阶段 (5-10年)

- **目标**：引领方向，创新突破
- **学习重点**
    - 前沿研究跟踪
    - 系统架构设计
    - 团队领导与项目管理
- **实践项目**
    - 提出原创性研究方向
    - 构建创新性TTS系统
    - 指导初学者，培养人才
